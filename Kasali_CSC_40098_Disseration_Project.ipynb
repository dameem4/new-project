{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "6GPXXZvRedrX",
        "QZ5xmqzjFiqv",
        "v7Zz96DHvufe",
        "GOsKxSfZbCIX",
        "ooL6a8rV0s9H",
        "ZJ_dAfRLt9hI",
        "KGrBm27j8Qcr",
        "9V_Q1g7cZDuL",
        "HJeiXIYMpsf_",
        "30nhpSTzt272",
        "wdUESoKqHZ1g",
        "V8J2EhNrHcM6"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dameem4/new-project/blob/master/Kasali_CSC_40098_Disseration_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDpFbmTe4usX"
      },
      "source": [
        "# Table of Contents\n",
        "\n",
        "<details><summary>\n",
        "<font color='Blue'> I. Installation of MMF & dependencies </font></summary>\n",
        "\n",
        "- Install MMF from source\n",
        "</details>\n",
        "\n",
        "<details><summary>\n",
        "<font color='Blue'> II. Download the datasets & convert them into MMF format </font></summary>\n",
        "\n",
        "\n",
        "</details>\n",
        "\n",
        "\n",
        "<details><summary>\n",
        "<font color='Blue'> III. Feature Extraction </font></summary>\n",
        "\n",
        "</details>\n",
        "\n",
        "<details><summary>\n",
        "<font color='Blue'> IV. Fine-tuning pre-trained VisualBERT models on Hateful Memes </font></summary>\n",
        "\n",
        "</details>\n",
        "\n",
        "\n",
        "<details><summary>\n",
        "<font color='Blue'> V. Generate predictions for the Challenge (`test_unseen.jsonl`) </font></summary>\n",
        "\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kE9_rJZfF_Rf"
      },
      "source": [
        "## <font color='green'> <b> I. Installation of MMF & dependencies </b> </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7V112rAEiK9"
      },
      "source": [
        "Please set your `$HOME` directory.\\\n",
        "**e.g.** For *Linux* users it can be: `\"/home\"`,\\\n",
        "For *Colab* it would be: `\"/content\"`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ATqmsZVmEhXc",
        "outputId": "6d514591-76ef-43a1-a529-f2467f6071af"
      },
      "source": [
        "import os\n",
        "home = \"/content\"\n",
        "os.chdir(home)\n",
        "os.getcwd()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JeJ7JdvoKPB"
      },
      "source": [
        "# Install specified versions of `torch` and `torchvision`, before installing mmf (causes an issue)\n",
        "!pip install torch torchvision -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rna7NAZtwaod"
      },
      "source": [
        "#### *Install MMF from source* \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtyIgblgvdoY"
      },
      "source": [
        "# Clone the following repo where mmf does not install default image features, \n",
        "# since we will use our own features\n",
        "!git clone https://github.com/facebookresearch/mmf.git\n",
        "%cd /content/mmf\n",
        "!pip install --editable ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf mmf"
      ],
      "metadata": {
        "id": "N9ExXvGgNUTa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHzXv9ogv3K8"
      },
      "source": [
        "os.chdir(os.path.join(home, \"mmf\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyX6Qos3Olyg"
      },
      "source": [
        "---\n",
        "## <font color='green'> <b> II. Download the datasets & convert them into *MMF* format </b> </font> <font color='red'><b> --Action required!-- </b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHJeqCgrEb_c"
      },
      "source": [
        "### <font color='Orchid'> <b> Hateful Memes  dataset </b> </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please download the `Hateful Memes Dataset` from the official challenge webpage: https://hatefulmemeschallenge.com/#download\n",
        "\n",
        "After filling the form the `hateful_memes.zip` file will be downloaded, which includes all the required data including images. Please define the variable `PATH_TO_ZIP_FILE` in the following code cell which stores the full path of the downloaded `.zip` file:\n"
      ],
      "metadata": {
        "id": "9JXlUJY4nZsN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PATH_TO_ZIP_FILE = \"/content/drive/Othercomputers/MyLaptop/memes/hateful_memes.zip\"\n",
        "!cp -r $PATH_TO_ZIP_FILE /content/mmf/"
      ],
      "metadata": {
        "id": "FyBgXNuBn8yi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-iyIDajcnTrx",
        "outputId": "fa946544-b140-49dd-a29c-f5b619b4aa13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mmf"
      ],
      "metadata": {
        "id": "fP0goEU5Mgsv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add the mmf folder to Python Path\n",
        "os.environ['PYTHONPATH'] += \":/content/mmf/\""
      ],
      "metadata": {
        "id": "klaSRv6pqyaD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TJqJoKnoc1B"
      },
      "source": [
        "!mmf_convert_hm --zip_file=\"hateful_memes.zip\" --password DontTellYou"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mmf"
      ],
      "metadata": {
        "id": "F-DoI_i7Fvq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gb8KJT1aBWzr"
      },
      "source": [
        "# Check how many images we have in total\n",
        "!ls /root/.cache/torch/mmf/data/datasets/hateful_memes/defaults/images/img/ | wc -l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8txdoDJgV5H-"
      },
      "source": [
        "That means there are `12.140` **'uniquely named'** images in total and you might recall that the sizes of each set was the following:\n",
        "\n",
        "- `|train.jsonl| = 8.500`\n",
        "- `|dev_seen.jsonl| = 500`\n",
        "- `|dev_unseen.jsonl| = 540`\n",
        "- `|test_seen.jsonl| = 1.000`\n",
        "- `|test_unseen.jsonl| = 2.000`\n",
        "\n",
        "Well, this makes `8.500 + 500 + 540 + 1.000 + 2.000 = 12.540` in total. \\\n",
        "> *Is there something wrong?*\\\n",
        "> **TL;DR:** Nope. Some images in `dev_seen` are used in `dev_unseen`, too. To be specific, they have `400` common images. Hence, in total we have `12.540 - 400 = 12.140` *'unique'* images.\\\n",
        "See <font color='orange'> <b> Extras </b> </font> --> <font color='Gold'><b> Number of 'unique' (based on file names) images </b></font> at the end of this script to see the explanation in detail."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKUDTNzLxvXf"
      },
      "source": [
        "# Free up the disk by removing .zip, .tar files\n",
        "!rm -rf /root/.cache/torch/mmf/data/datasets/hateful_memes/defaults/images/hateful_memes.zip\n",
        "!rm -rf $home/mmf/hateful_memes.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8eECHBkozZ8R"
      },
      "source": [
        "### <font color='Orchid'> <b> Memotion dataset </b> </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KVJRAfSDLlR"
      },
      "source": [
        "There are 2 options for downloading the dataset: \n",
        "1. download the dataset (a `.zip` file) using `Kaggle API`\\\n",
        "OR\n",
        "2. download the dataset (a `.zip` file) from [Kaggle](https://www.kaggle.com/williamscott701/memotion-dataset-7k) directly, **(<font color='red' >preferred </font> if you're not familiar with Kaggle API)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feH6betK2mqB"
      },
      "source": [
        "#### <font color='Thistle'> <b> 1. Download Memotion dataset using `Kaggle API` </b> </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgtqtKPGpKQb"
      },
      "source": [
        "Check out the official documentation to get more information on Kaggle API and how to create a Kaggle API Key:\n",
        "- [Link#1](https://github.com/Kaggle/kaggle-api#api-credentials)\n",
        "- [Link#2](https://www.kaggle.com/docs/api)\n",
        "\n",
        "The API Key is stored in a file named `kaggle.jsonl`, which has the folowing line inside: \n",
        "`{\"username\":\"your_user_name\",\"key\":\"some_values_here\"}`\n",
        "\n",
        "> Upload the `kaggle.json` file to your `$HOME` directory and run the following cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgWGOly32rnV"
      },
      "source": [
        "# Install kaggle library\n",
        "!pip install -q kaggle\n",
        "# Create a directory where API key will be stored\n",
        "!mkdir -p ~/.kaggle\n",
        "# Move the API key to where Kaggle expects it to be\n",
        "!mv $home/kaggle.json ~/.kaggle/\n",
        "# Give according rights to the file\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "# Finally, download the dataset (.zip file)\n",
        "!kaggle datasets download -d williamscott701/memotion-dataset-7k\n",
        "# Unzip the data \n",
        "!unzip -qq memotion-dataset-7k.zip -d $home/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PFMUbGc2rzy"
      },
      "source": [
        "#### <font color='Thistle'> <b> 2. Download Memotion dataset directly from [Kaggle](https://www.kaggle.com/williamscott701/memotion-dataset-7k) </b> </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9FJiGtSLEsI4"
      },
      "source": [
        "Download the dataset and put the `.zip` file into your `$HOME` directory and then run the following cell:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QNouszeEo8i"
      },
      "source": [
        "# Unzip the data \n",
        "# !unzip memotion-dataset-7k.zip -d $home/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwaTcWOctsA8"
      },
      "source": [
        "#### <font color='Thistle'> <b> Labeling Memotion Dataset </b> </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "791PwkoLFGmD"
      },
      "source": [
        "We have added `Memotion Dataset` to `Hateful Memes Dataset` and fine-tuned some models on the *aggregated* data. But there was no significant improvement seen neither on the `ROC-AUC score`, nor on the `accuracy`. We then discovered that the dataset is *horribly* labeled. Therefore, one needs to label the dataset.\n",
        "\n",
        "So we went through the dataset and cherry-picked the memes that would be suitable for the challenge, considering the idea of `Hateful Memes Challenge`.\n",
        "\n",
        "The following cell can be run to clone a repository which includes helpful scripts for the project such as; a script for labeling the `Memotion Dataset` and saving the data in the same format as the `Hateful Memes Dataset`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRqJ83FrVmSp",
        "outputId": "57508694-c3b2-4b19-c080-e4d3e1d2091b"
      },
      "source": [
        "os.chdir(home)\n",
        "!git clone https://github.com/facebookresearch/detectron2.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'hateful_memes-hate_detectron'...\n",
            "remote: Enumerating objects: 47, done.\u001b[K\n",
            "remote: Counting objects: 100% (47/47), done.\u001b[K\n",
            "remote: Compressing objects: 100% (31/31), done.\u001b[K\n",
            "remote: Total 47 (delta 19), reused 43 (delta 15), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (47/47), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZG2LoOnX23V"
      },
      "source": [
        "Labeling the dataset is not necessary for reproducing our results but one can check out the [labeling script](https://github.com/rizavelioglu/hateful_memes-hate_detectron/tree/main/utils/label_memotion.py) and execute the following line of code to run the script and see how the labeling is done.\n",
        "\n",
        "```\n",
        "# Start labeling Memotion dataset and save it at the end\n",
        "%run $home/hateful_memes-hate_detectron/utils/label_memotion.py --home $home\n",
        "```\n",
        "\n",
        "---\n",
        "> In total, we have labeled $328$ memes.\\\n",
        "Check out the following file to find the ones we labeled: [/hateful_memes-hate_detectron/utils/label_memotion.jsonl](https://github.com/rizavelioglu/hateful_memes-hate_detectron/tree/main/utils/label_memotion.jsonl)\n",
        "\n",
        "Next, we move those labeled images from `Memotion Dataset` into the same folder where the images from `Hateful Memes Dataset` are, so that when the image features are being extracted all the images are inside the same folder.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrmqLTIhu_Mc"
      },
      "source": [
        "import pandas as pd\n",
        "# read the .jsonl file and get the img column\n",
        "labeled_memo_samples = pd.read_json(os.path.join(home, \"hateful_memes-hate_detectron/utils/label_memotion.jsonl\"), lines=True)['img']\n",
        "# parse the img entries and get the image names\n",
        "labeled_memo_samples = [i.split('/')[1] for i in list(labeled_memo_samples)]\n",
        "\n",
        "img_dir = os.path.join(home, f\"memotion_dataset_7k/images/\")\n",
        "for img in labeled_memo_samples:\n",
        "    os.rename(f\"{img_dir+img}\", f\"/root/.cache/torch/mmf/data/datasets/hateful_memes/defaults/images/img/{img}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlCn72uPUxF_",
        "outputId": "cb60f1da-d182-435b-f458-5f7e41f61f76"
      },
      "source": [
        "# Check how many images we have in total\n",
        "!ls /root/.cache/torch/mmf/data/datasets/hateful_memes/defaults/images/img/ | wc -l"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12468\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tu5bDeGm8Q-c"
      },
      "source": [
        "### <font color='Orchid'> <b> Merging the two datasets to get a larger training data</b> </font>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVYF-w_aCxWV"
      },
      "source": [
        "Simply execute the following cell which concatanates;\n",
        "- Labeled Memotion dataset,\n",
        "- Hateful Memes' training data, and\n",
        "- 100 images from `dev_seen.jsonl` that are not in `dev_unseen.jsonl`\n",
        "\n",
        "and generates `train_v10.jsonl`, which will be used for fine-tuning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUL8Tgkh8WUz"
      },
      "source": [
        "!python $home/hateful_memes-hate_detectron/utils/concat_memotion-hm.py --home $home"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzAxev4zeXxx"
      },
      "source": [
        "---\n",
        "## <font color='green'> <b> III. Feature Extraction </b> </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CTm-rxS0e97"
      },
      "source": [
        "### <font color='lightgreen'> <b> Extract image features using [`mmf/tools/scripts/features/extract_features_vmb.py`](https://github.com/facebookresearch/mmf/blob/master/tools/scripts/features/extract_features_vmb.py) </b> </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yq5AjtXH74Ep"
      },
      "source": [
        "#### Install packages & repos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQfgIJ-004A5"
      },
      "source": [
        "import os\n",
        "os.chdir(home)\n",
        "!git clone https://gitlab.com/vedanuj/vqa-maskrcnn-benchmark"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4Lkv0F3-3pD"
      },
      "source": [
        "!pip install ninja yacs cython matplotlib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCzMvexR6so_"
      },
      "source": [
        "os.chdir(os.path.join(home, \"vqa-maskrcnn-benchmark\"))\n",
        "!rm -rf build\n",
        "!python setup.py build develop"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oj_Fwxta79d2"
      },
      "source": [
        "#### Extract!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLFTDh735BDr"
      },
      "source": [
        "# !wget https://dl.fbaipublicfiles.com/pythia/detectron_model/FAST_RCNN_MLP_DIM2048_FPN_DIM512.pkl\n",
        "# !wget https://dl.fbaipublicfiles.com/pythia/detectron_model/e2e_faster_rcnn_X-101-64x4d-FPN_1x_MLP_2048_FPN_512.yaml\n",
        "os.chdir(os.path.join(home, \"mmf/tools/scripts/features/\"))\n",
        "out_folder = os.path.join(home, \"features/\")\n",
        "\n",
        "!python extract_features_vmb.py --config_file \"https://dl.fbaipublicfiles.com/pythia/detectron_model/detectron_model_x152.yaml\" \\\n",
        "                                --model_name \"X-152\" \\\n",
        "                                --output_folder $out_folder \\\n",
        "                                --image_dir \"/root/.cache/torch/mmf/data/datasets/hateful_memes/defaults/images/img/\" \\\n",
        "                                --num_features 100 \\\n",
        "                                # --exclude_list \"/content/exclude.txt\"\n",
        "                                # --feature_name \"fc6\" \\\n",
        "                                # --confidence_threshold 0. \\"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJ19s6lUiL9w"
      },
      "source": [
        "---\n",
        "## <font color='green'> <b> IV. Fine-tuning pre-trained VisualBERT models on Hateful Memes </b> </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZyV2LQGAgB1"
      },
      "source": [
        "*italicised text*### <font color='Violet'> <b> Fine tuning  </b> </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKfM87TjYpxY"
      },
      "source": [
        "\"\"\"\n",
        "Uncomment it if needed\n",
        "\"\"\"\n",
        "\n",
        "# os.chdir(home)\n",
        "# # Define where image features are\n",
        "# feats_dir = os.path.join(home, \"features\")\n",
        "# # Define where train.jsonl is\n",
        "# train_dir = os.path.join(home, \"train_v9.jsonl\")\n",
        "\n",
        "# !mmf_run config=\"projects/visual_bert/configs/hateful_memes/from_coco.yaml\" \\\n",
        "#         model=\"visual_bert\" \\\n",
        "#         dataset=hateful_memes \\\n",
        "#         run_type=train_val \\\n",
        "#         checkpoint.max_to_keep=1 \\\n",
        "#         checkpoint.resume_zoo=visual_bert.pretrained.cc.full \\\n",
        "#         training.tensorboard=True \\\n",
        "#         training.checkpoint_interval=50 \\\n",
        "#         training.evaluation_interval=50 \\\n",
        "#         training.max_updates=3000 \\\n",
        "#         training.log_interval=100 \\\n",
        "#         dataset_config.hateful_memes.max_features=100 \\\n",
        "#         dataset_config.hateful_memes.annotations.train[0]=$train_dir \\\n",
        "#         dataset_config.hateful_memes.annotations.val[0]=hateful_memes/defaults/annotations/dev_unseen.jsonl \\\n",
        "#         dataset_config.hateful_memes.annotations.test[0]=hateful_memes/defaults/annotations/test_unseen.jsonl \\\n",
        "#         dataset_config.hateful_memes.features.train[0]=$feats_dir \\\n",
        "#         dataset_config.hateful_memes.features.val[0]=$feats_dir \\\n",
        "#         dataset_config.hateful_memes.features.test[0]=$feats_dir \\\n",
        "#         training.lr_ratio=0.3 \\\n",
        "#         training.use_warmup=True \\\n",
        "#         training.batch_size=32 \\\n",
        "#         optimizer.params.lr=5.0e-05 \\\n",
        "#         env.save_dir=./sub1 \\\n",
        "#         env.tensorboard_logdir=logs/fit/sub1 \\"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5BfCb_YdeX4"
      },
      "source": [
        "##### **Visualize losses/accuracy via Tensorboard**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jeFuYAVzI_Nx"
      },
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "# %load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVB4eQ1gOw4j"
      },
      "source": [
        "# %tensorboard --logdir logs/fit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTUjwxmHGxVm"
      },
      "source": [
        "---\n",
        "## <font color='green'> <b> V. Generate predictions for the Challenge (`test_unseen.jsonl`) </b> </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8zO7Tj98Nfp"
      },
      "source": [
        "*italicised text*### <font color='Thistle'> <b> Testing Phase 1 </b> </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GB3EFVnMIC9h"
      },
      "source": [
        "\"\"\"\n",
        "Uncomment it if needed\n",
        "\"\"\"\n",
        "\n",
        "# os.chdir(home)\n",
        "# # where checkpoint is\n",
        "# ckpt_dir = os.path.join(home, \"sub1/best.ckpt\")\n",
        "# feats_dir = os.path.join(home, \"features/feats_hm\")\n",
        "\n",
        "# !mmf_predict config=\"projects/visual_bert/configs/hateful_memes/defaults.yaml\" \\\n",
        "#     model=\"visual_bert\" \\\n",
        "#     dataset=hateful_memes \\\n",
        "#     run_type=test \\\n",
        "#     checkpoint.resume_file=$ckpt_dir \\\n",
        "#     checkpoint.reset.optimizer=True \\\n",
        "#     dataset_config.hateful_memes.annotations.val[0]=hateful_memes/defaults/annotations/dev_unseen.jsonl \\\n",
        "#     dataset_config.hateful_memes.annotations.test[0]=hateful_memes/defaults/annotations/test_unseen.jsonl \\\n",
        "#     dataset_config.hateful_memes.features.train[0]=$feats_dir \\\n",
        "#     dataset_config.hateful_memes.features.val[0]=$feats_dir \\\n",
        "#     dataset_config.hateful_memes.features.test[0]=$feats_dir \\"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GPXXZvRedrX"
      },
      "source": [
        "\n",
        "### <font color='Gold'> <b> Image feature type conversion </b> </font>\n",
        "Convert image features from `.npy` --> `.lmdb` and vice versa\n",
        "\n",
        "You can also try to use the .npy files directly. Just point to the folder which contains those files in your config. lmdb is not a necessary requirement."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZ5xmqzjFiqv"
      },
      "source": [
        "#### <font color='PaleGoldenrod'> <b> Convert .npy files to .lmdb </b> </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0N_mJ5MQFlKe"
      },
      "source": [
        "import argparse\n",
        "import glob\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "import lmdb\n",
        "import numpy as np\n",
        "import tqdm\n",
        "\n",
        "\n",
        "class LMDBConversion():\n",
        "    def __init__(self, features_folder, lmdb_path):\n",
        "        self.features_folder = features_folder\n",
        "        self.lmdb_path = lmdb_path\n",
        "\n",
        "    def convert(self):\n",
        "        env = lmdb.open(self.lmdb_path, map_size=1099511627776)\n",
        "        id_list = []\n",
        "        features = glob.glob(\n",
        "            os.path.join(self.features_folder, \"**\", \"*.npy\"), recursive=True\n",
        "        )\n",
        "\n",
        "\n",
        "        with env.begin(write=True) as txn:\n",
        "            for infile in tqdm.tqdm(features):\n",
        "                reader = np.load(infile, allow_pickle=True)\n",
        "                item = {}\n",
        "                split = os.path.relpath(infile, self.features_folder).split(\n",
        "                    \".npy\"\n",
        "                )[0]\n",
        "                item[\"feature_path\"] = split\n",
        "                key = split.encode()\n",
        "                id_list.append(key)\n",
        "\n",
        "                item[\"features\"] = reader.item().get(\"features\")\n",
        "                item[\"image_height\"] = reader.item().get(\"image_height\")\n",
        "                item[\"image_width\"] = reader.item().get(\"image_width\")\n",
        "                item[\"num_boxes\"] = reader.item().get(\"num_boxes\")\n",
        "                item[\"objects\"] = reader.item().get(\"objects\")\n",
        "                item[\"cls_prob\"] = reader.item().get(\"cls_prob\", None)\n",
        "                item[\"bbox\"] = reader.item().get(\"bbox\")\n",
        "\n",
        "                txn.put(key, pickle.dumps(item))\n",
        "\n",
        "            txn.put(b\"keys\", pickle.dumps(id_list))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCEy9BfnFsVW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "39cf2c61-5558-4d7d-db6c-27d9d0ad002b"
      },
      "source": [
        "features_folder = '/content/features/'\n",
        "lmdb_path = \"/content/\"\n",
        "lmdb_converter = LMDBConversion(features_folder, lmdb_path)\n",
        "lmdb_converter.convert()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 16522/16522 [01:30<00:00, 181.86it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7Zz96DHvufe"
      },
      "source": [
        "#### <font color='PaleGoldenrod'> <b> Convert .lmdb to .npy </b> </font>\n",
        "just to check if everything's okay"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_4VqHRlLBz_"
      },
      "source": [
        "features_folder = \"/content/features_from_lmdb/\"\n",
        "lmdb_path = \"/content/drive/MyDrive/\"\n",
        "\n",
        "def extract():\n",
        "    os.makedirs(features_folder, exist_ok=True)\n",
        "    env = lmdb.open(\n",
        "        lmdb_path,\n",
        "        max_readers=1,\n",
        "        readonly=True,\n",
        "        lock=False,\n",
        "        readahead=False,\n",
        "        meminit=False,\n",
        "    )\n",
        "    with env.begin(write=False) as txn:\n",
        "        _image_ids = pickle.loads(txn.get(b\"keys\"))\n",
        "        for img_id in tqdm.tqdm(_image_ids):\n",
        "            item = pickle.loads(txn.get(img_id))\n",
        "            img_id = img_id.decode(\"utf-8\")\n",
        "            \n",
        "            tmp_dict = {\n",
        "                \"image_id\"    : img_id,\n",
        "                \"bbox\"        : item[\"bbox\"],\n",
        "                \"num_boxes\"   : item[\"num_boxes\"],\n",
        "                \"image_height\": item[\"image_height\"],\n",
        "                \"image_width\" : item[\"image_width\"],\n",
        "                \"objects\"     : item[\"objects\"],\n",
        "                \"cls_prob\"    : item[\"cls_prob\"],\n",
        "            }\n",
        "\n",
        "            info_file_base_name = str(img_id) + \"_info.npy\"\n",
        "            file_base_name = str(img_id) + \".npy\"\n",
        "\n",
        "            np.save(\n",
        "                os.path.join(features_folder, file_base_name),\n",
        "                item[\"features\"],\n",
        "            )\n",
        "            np.save(\n",
        "                os.path.join(features_folder, info_file_base_name),\n",
        "                tmp_dict,\n",
        "            )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MiU5UlJZLdyg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "97c35a12-00e3-4797-dd2d-cade53633aef"
      },
      "source": [
        "extract()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 16522/16522 [04:24<00:00, 62.54it/s] \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_yEziJrtG_E"
      },
      "source": [
        "data = np.load(\"/content/features_from_lmdb/01243.npy\", allow_pickle=True)\n",
        "data_info = np.load(\"/content/features_from_lmdb/01243_info.npy\", allow_pickle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAiWj4QetV-9"
      },
      "source": [
        "data_info.item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4apQdfQzaQG"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOsKxSfZbCIX"
      },
      "source": [
        "### <font color='Gold'><b> Number of 'unique' (based on file names) images </b></font>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_ipIAgOa_kd"
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "annotation_dir = \"/root/.cache/torch/mmf/data/datasets/hateful_memes/defaults/annotations\"\n",
        "img_dir = \"/root/.cache/torch/mmf/data/datasets/hateful_memes/defaults/images/img/\"\n",
        "\n",
        "# Collect all the annotations (from Phase-2)\n",
        "train       = pd.read_json(f\"{annotation_dir}/train.jsonl\", lines=True)\n",
        "dev_seen    = pd.read_json(f\"{annotation_dir}/dev_seen.jsonl\", lines=True)\n",
        "dev_unseen  = pd.read_json(f\"{annotation_dir}/dev_unseen.jsonl\", lines=True)\n",
        "test_seen   = pd.read_json(f\"{annotation_dir}/test_seen.jsonl\", lines=True)\n",
        "test_unseen = pd.read_json(f\"{annotation_dir}/test_unseen.jsonl\", lines=True)\n",
        "\n",
        "# Create 2 sets: \n",
        "#   A set of strings, 'a': for all the image names,\n",
        "#   A set of lists, 'b': for all the image names in dataset, e.g. train, dev_seen, etc.\n",
        "a = os.listdir(f\"{img_dir}\")\n",
        "b = []\n",
        "for i in [train, dev_seen, dev_unseen, test_seen, test_unseen]:\n",
        "    b.append(list(i[\"img\"].str.split(\"/\").str.get(1)))\n",
        "\n",
        "set_mapping = ['train', 'dev_seen', 'dev_unseen', 'test_seen', 'test_unseen']\n",
        "total_size = 0\n",
        "print(\"#of images in: \")\n",
        "for idx, i in enumerate(b):\n",
        "    total_size += len(set(i))\n",
        "    print(f\"\\t'{set_mapping[idx]}'  \\t:\", len(set(i)))\n",
        "else:\n",
        "    print(f\"\\nIn total there are {total_size} images,\",\n",
        "          \"\\nBut the # of images in /img/ directory is: \", len(a))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-SFAVsnmqcw"
      },
      "source": [
        "# First, let's check if all the images are within jsonl files, in other words: \n",
        "# 'do we have an image in /img folder that's not in one of the .jsonl files?'\n",
        "# 0 means every image in /img directory is in a jsonl file\n",
        "print(\"#of images that are not in one of the .jsonl files: \", \n",
        "      len(set(a).symmetric_difference(set(b[0] + b[1] + b[2] + b[3] + b[4]))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPuWl4ZCq28s"
      },
      "source": [
        "print(\"#of same images in between: \")\n",
        "for i in range(0, 5):\n",
        "    print(\"\\n\")\n",
        "    for j in range(0, 5):\n",
        "        if i != j:\n",
        "            print(f\"{set_mapping[i], set_mapping[j]}   \\t: {len(set(b[i]) & set(b[j]))}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-004uK7hv3p"
      },
      "source": [
        "As seen, `dev_seen.jsonl` and `dev_unseen.jsonl` have `400` same images. Let's double check that:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_W3G8kkjw0S"
      },
      "source": [
        "print(f\"#of same images in {set_mapping[1], set_mapping[2]}: {len(set(b[1]) & set(b[2]))}\",\n",
        "      f\"\\n#of different images: {len(set(b[1]).symmetric_difference(set(b[2])))}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZXyn01tvhN_"
      },
      "source": [
        "That means in Phase-2, `100` images were removed from `dev_seen.jsonl` and `140` new images are added to the validation set.\\\n",
        "Hence;  `|dev_unseen.jsonl|=500-100+140=540`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ooL6a8rV0s9H"
      },
      "source": [
        "### <font color='Gold'> <b> Image Feature Extraction </b> </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJ_dAfRLt9hI"
      },
      "source": [
        "#### <font color='PaleGoldenrod'> <b> Discovering default image features from MMF </b> </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPLWtTofNUf_"
      },
      "source": [
        "Download the features for Phase-2 which was published by MMF on 01.10.2020 [[source of link]](https://github.com/facebookresearch/mmf/blob/518a5a675586e4dc1b415a52a8a80c75edfc2960/mmf/configs/zoo/datasets.yaml#L232)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtBCSXYHKzod"
      },
      "source": [
        "# Download the features for Phase-2 from the following link\n",
        "!wget https://dl.fbaipublicfiles.com/mmf/data/datasets/hateful_memes/defaults/features/features_2020_10_01.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SF6cDF4MQ6qU"
      },
      "source": [
        "Extract `features_2020_10_01.tar.gz`:\n",
        "> this file actually extracts a folder `detectron.lmdb/` which\n",
        "stores the `data.mdb` file, which is where all the image features are compressed into."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKxRLf3QO27b"
      },
      "source": [
        "!tar -xzf /content/features_2020_10_01.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLUqOVApWsZq"
      },
      "source": [
        "Extract image features from `detectron.lmdb/` folder to `/features/`.\n",
        "\n",
        "**Note**\n",
        "Interrupt the execution as we only want to have a sneek peek into a few features. So, no need to extract the whole image features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkj0TfSkq6zi"
      },
      "source": [
        "!python /content/mmf/tools/scripts/features/lmdb_conversion.py \\\n",
        "        --mode \"extract\" \\\n",
        "        --lmdb_path \"/content/detectron.lmdb\" \\\n",
        "        --features_folder \"/content/features/\" \\"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_JWVeOYvJsM"
      },
      "source": [
        "# Load only one image feature\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "img_list = os.listdir(\"/content/features/\")\n",
        "feat_dir = \"/content/features/\"\n",
        "\n",
        "\n",
        "if len(img_list[0].split('_'))==2:\n",
        "    img_id = img_list[0].split('_')[0]\n",
        "else:\n",
        "    img_id = img_list[0].split('_')[0].split('.')[0]\n",
        "\n",
        "# There are 2 .npy files for each image, \n",
        "#   e.g. : for the image with 'image_id=75349':\n",
        "#       - '75349.npy' : actual feature embedding\n",
        "#       - '75349_info.npy' : meta-data about the image\n",
        "data      = np.load(f\"{feat_dir + img_id}.npy\", allow_pickle=True)\n",
        "data_info = np.load(f\"{feat_dir + img_id}_info.npy\", allow_pickle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJIyYjD_yeIM"
      },
      "source": [
        "# Images are embedded to 2048 dimension!\n",
        "# There are 100 bbox's\n",
        "data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SIf3EuIy1U8"
      },
      "source": [
        "# The meta-data about the image\n",
        "data_info.item().keys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y648iYbLqgfj"
      },
      "source": [
        "print(f\"image_id\\t: {data_info.item()['image_id']}\",\n",
        "      f\"\\nnum_boxes\\t: {data_info.item()['num_boxes']}\",\n",
        "      f\"\\nimage_height\\t: {data_info.item()['image_height']}\",\n",
        "      f\"\\nimage_width\\t: {data_info.item()['image_width']}\",\n",
        "      f\"\\nshape(bbox)\\t: {data_info.item()['bbox'].shape}\",\n",
        "      f\"\\nshape(objects)\\t: {data_info.item()['objects'].shape}\",\n",
        "      f\"\\nshape(cls_prob)\\t: {data_info.item()['cls_prob'].shape}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmIygFhyz1u2"
      },
      "source": [
        "data_info.item()[\"objects\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2wJZAFZ2EEB"
      },
      "source": [
        "for i in [0, 1, 2]:\n",
        "  print(f\"max cls_prob of box #{[i]}: {data_info.item()['cls_prob'][i].max()}\",\n",
        "        f\"\\nindex of that class\\t: {data_info.item()['cls_prob'][i].argmax()}\\n\",\n",
        "        \"-\"*10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36-yi-0G0gTI"
      },
      "source": [
        "data_info.item()[\"bbox\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGrBm27j8Qcr"
      },
      "source": [
        "#### <font color='PaleGoldenrod'> <b> Different techniques for image feature extraction </b> </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9V_Q1g7cZDuL"
      },
      "source": [
        "##### <font color='PeachPuff'> <b> Extract image features using `Detectron2` & `ResNet-152` </b> </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2Lb6CYtG5Ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "f18f72f2-056a-41f1-9d07-4dce6765df33"
      },
      "source": [
        "!python extract_region_feature.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0% 0/3 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/detectron2/modeling/poolers.py:231: UserWarning: This overload of nonzero is deprecated:\n",
            "\tnonzero(Tensor input, *, Tensor out)\n",
            "Consider using one of the following signatures instead:\n",
            "\tnonzero(Tensor input, *, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:766.)\n",
            "  inds = torch.nonzero(level_assignments == level).squeeze(1)\n",
            "100% 3/3 [00:20<00:00,  6.84s/it]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amSAhPpfNVSZ"
      },
      "source": [
        "data = np.load(\"/content/features/hateful_memes/image_1.npy\", allow_pickle=True)\n",
        "data.item(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGneRiZ-NiUR"
      },
      "source": [
        "data.item(0)[\"features\"].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nid0HIoXru5Z"
      },
      "source": [
        "data.item().keys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJeiXIYMpsf_"
      },
      "source": [
        "##### <font color='PeachPuff'> <b> Extract image features using [`facebookresearch/grid-feats-vqa`](https://github.com/facebookresearch/grid-feats-vqa) </b> </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAqqZtLEpZr7"
      },
      "source": [
        "# Install required packages\n",
        "!pip install -U git+https://github.com/facebookresearch/fvcore\n",
        "!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git@ffff8ac'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pvr-E4zQjBmr"
      },
      "source": [
        "!git clone https://github.com/vedanuj/grid-feats-vqa.git --branch region_features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nQadBYTlFq1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "590bb320-fa21-4c3c-aab7-21010f7acb0d"
      },
      "source": [
        "cd grid-feats-vqa/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/grid-feats-vqa\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_pUuWxokuNO"
      },
      "source": [
        "!python extract_region_feature.py \\\n",
        "              --config-file configs/X-152-region-c4.yaml \\\n",
        "              --dataset \"hateful_memes\" \\\n",
        "              --dataset-path \"/root/.cache/torch/mmf/data/datasets/hateful_memes/defaults/images/img/\" \\"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVRUiTnJo8hc"
      },
      "source": [
        "!ls /content/grid-feats-vqa/output/features/hateful_memes/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWtlK_rNE-hr"
      },
      "source": [
        "import numpy as np\n",
        "data = np.load(\"/content/grid-feats-vqa/output/features/hateful_memes/01235.npy\", allow_pickle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMGaBDdWGTJO"
      },
      "source": [
        "data.item(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "paTNe9abIcqY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4c387dbc-d16f-4000-8506-c24ff5416045"
      },
      "source": [
        "data.item(0)[\"bbox\"].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30nhpSTzt272"
      },
      "source": [
        "##### <font color='PeachPuff'> <b> Extract image features using [`airsplay/py-bottom-up-attention`](https://github.com/airsplay/py-bottom-up-attention) </b> </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdUESoKqHZ1g"
      },
      "source": [
        "###### **Install packages**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ZMo24Yjof56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "3bd3f3c3-ae32-4fec-fb4d-9a15e7eca8b8"
      },
      "source": [
        "import os\n",
        "os.chdir(\"/content/\")\n",
        "!git clone https://github.com/airsplay/py-bottom-up-attention.git\n",
        "os.chdir(\"py-bottom-up-attention/\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'py-bottom-up-attention'...\n",
            "remote: Enumerating objects: 1991, done.\u001b[K\n",
            "remote: Total 1991 (delta 0), reused 0 (delta 0), pack-reused 1991\u001b[K\n",
            "Receiving objects: 100% (1991/1991), 8.94 MiB | 34.95 MiB/s, done.\n",
            "Resolving deltas: 100% (1225/1225), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8GLLejupnTF"
      },
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGqAbI9qpyCh"
      },
      "source": [
        "!pip install 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'\n",
        "# Install detectron2\n",
        "!python setup.py build develop"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8J2EhNrHcM6"
      },
      "source": [
        "###### **Extract!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgWtSfIJf-qX"
      },
      "source": [
        "os.chdir(\"/content/hateful_memes/region_feature_extraction/\")\n",
        "!python extract.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDjsV5jDAQpi"
      },
      "source": [
        "!ls /content/features/ | wc -l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEwh34kXBzOc"
      },
      "source": [
        "*What is the size of the training data?*\n",
        "> \n",
        "\n",
        "*Did you use additional dataset?*\n",
        "> Yes. I used Memotion as an additional dataset\n",
        "\n",
        "*Did you use pre-trained models?*\n",
        "> Yes. I used `VisualBERT` which was pre-trained on `Masked Conceptual Captions` dataset, see <font color='magenta'> <b> IV. Fine-tuning pre-trained VisualBERT models on Hateful Memes </b> </font>. Then, the model was fine-tuned on the HM dataset. The pre-trained model is available from MMF: [See all the available pre-trained VisualBERT models from MMF](https://github.com/facebookresearch/mmf/tree/master/projects/pretrain_vl_right)\n",
        "\n",
        "*Did you use default image features provided by MMF?*\n",
        "> No. I extracted our own image features using Facebook's Detectron model, which uses ResNet-152 as its backbone. See <font color='magenta'> <b> III. Feature Extraction </b> </font> part in the notebook.\n",
        "\n",
        "*What is the impact of `Majority Voting` technique in ROC-AUC score? And what do you think about the reason behind?*\n",
        ">\n",
        "\n",
        "**\n",
        ">"
      ]
    }
  ]
}